{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = \\\n",
    "    'http://download.tensorflow.org/models/object_detection/'\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "result_categories = ['4/5', '2/3', '>5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map,\n",
    "        max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_num(id):\n",
    "    try:\n",
    "        images = os.listdir(\"Myauto_data/Car_Images/Car_Images/{}\".format(id))\n",
    "    except:\n",
    "        return 0\n",
    "    return len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_image(path):\n",
    "    path = \"/Users/andghuladze/Documents/Vision/Myauto_data/Car_Images/Car_Images/{}\".format(path)\n",
    "    image = transform.resize(io.imread(path), (224, 224))/255\n",
    "    image = image[:, :, :3]\n",
    "\n",
    "    sample = torch.Tensor(np.einsum('ijk->kij', image))\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection_function(id):\n",
    "    total_passed_vehicle = 0\n",
    "    speed = 'waiting...'\n",
    "    direction = 'waiting...'\n",
    "    size = 'waiting...'\n",
    "    color = 'waiting...'\n",
    "    with detection_graph.as_default():\n",
    "        with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            car_data = []\n",
    "            img_number = get_max_num(id)\n",
    "            for i in range(1, img_number + 1):\n",
    "                input_frame = cv2.imread(\"Myauto_data/Car_Images/Car_Images/{}/{}.jpg\".format(id, i))\n",
    "\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(input_frame, axis=0)\n",
    "\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num) = \\\n",
    "                    sess.run([detection_boxes, detection_scores,\n",
    "                             detection_classes, num_detections],\n",
    "                             feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "                # Visualization of the results of a detection.\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    0,\n",
    "                    input_frame,\n",
    "                    boxes[0],\n",
    "                    classes[0].astype(np.int32),\n",
    "                    scores[0],\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=4\n",
    "                    )\n",
    "\n",
    "                for j in range(len(classes[0])):\n",
    "                    if classes[0][j] == 3 or classes[0][j] == 8:\n",
    "                        if scores[0][j] > 0.5:\n",
    "                            car_data.append(get_tensor_image(str(id) + \"/\" + str(i) + \".jpg\"))\n",
    "                            break\n",
    "                            \n",
    "            return car_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_init(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_init, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(models.resnet18(pretrained=True))\n",
    "        self.layers.append(nn.Linear(1000, 512)) \n",
    "        self.layers.append(nn.Dropout(0.1))\n",
    "        self.layers.append(nn.Linear(512, 64))\n",
    "        self.layers.append(nn.Dropout(0.1))\n",
    "        self.layers.append(nn.Linear(64, 3))\n",
    "        self.layers.append(nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init()\n",
    "model.load_state_dict(torch.load('models/doors_model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andghuladze/Python/venv_3.7/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "doors_csv = pd.read_csv(\"validation/doors_validation.csv\")\n",
    "original_result = []\n",
    "model_result = []\n",
    "\n",
    "for i in range(len(doors_csv)):\n",
    "    car_data = get_tensor_image(doors_csv.iloc[i].img_path[1:])\n",
    "    car_data = torch.stack([car_data])\n",
    "    result = model(car_data)\n",
    "    original_result.append(result_categories.index(doors_csv.iloc[i].Doors))\n",
    "    model_result = result.argmax().numpy()\n",
    "    \n",
    "print(classification_report(original_result, model_result))\n",
    "# car_data = torch.stack(object_detection_function(45801765))\n",
    "# result = model(car_data)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = result.sum(dim = 0)\n",
    "best_assumption = result_categories[sum.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAR DOORS NUM: 4/5\n"
     ]
    }
   ],
   "source": [
    "print(\"CAR DOORS NUM: \" + best_assumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
