{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car detection stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = \\\n",
    "    'http://download.tensorflow.org/models/object_detection/'\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.compat.v2.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map,\n",
    "        max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method counts image num in folder with given ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_num(id):\n",
    "    try:\n",
    "        images = os.listdir(\"/Users/andghuladze/Documents/Vision/Myauto_data/Car_Images/Car_Images/{}\".format(id))\n",
    "    except:\n",
    "        return 0\n",
    "    return len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method reads image from path and returns tensor image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_image(path):\n",
    "    path = \"/Users/andghuladze/Documents/Vision/Myauto_data/Car_Images/Car_Images/{}\".format(path)\n",
    "    image = transform.resize(io.imread(path), (224, 224))/255\n",
    "    image = image[:, :, :3]\n",
    "\n",
    "    sample = torch.Tensor(np.einsum('ijk->kij', image))\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This method returns car images in tensor on given ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection_function(id):\n",
    "    total_passed_vehicle = 0\n",
    "    speed = 'waiting...'\n",
    "    direction = 'waiting...'\n",
    "    size = 'waiting...'\n",
    "    color = 'waiting...'\n",
    "    with detection_graph.as_default():\n",
    "        with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            car_data = []\n",
    "            img_number = get_max_num(id)\n",
    "            for i in range(1, img_number + 1):\n",
    "                input_frame = cv2.imread(\"/Users/andghuladze/Documents/Vision/Myauto_data/Car_Images/Car_Images/{}/{}.jpg\".format(id, i))\n",
    "\n",
    "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                image_np_expanded = np.expand_dims(input_frame, axis=0)\n",
    "\n",
    "                # Actual detection.\n",
    "                (boxes, scores, classes, num) = \\\n",
    "                    sess.run([detection_boxes, detection_scores,\n",
    "                             detection_classes, num_detections],\n",
    "                             feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "                # Visualization of the results of a detection.\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    0,\n",
    "                    input_frame,\n",
    "                    boxes[0],\n",
    "                    classes[0].astype(np.int32),\n",
    "                    scores[0],\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=4\n",
    "                    )\n",
    "\n",
    "                for j in range(len(classes[0])):\n",
    "                    if classes[0][j] == 3 or classes[0][j] == 8:\n",
    "                        if scores[0][j] > 0.5:\n",
    "                            car_data.append(get_tensor_image(str(id) + \"/\" + str(i) + \".jpg\"))\n",
    "                            break\n",
    "                            \n",
    "            return car_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization. Using Resnet 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_init(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_init, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(models.resnet18(pretrained=True))\n",
    "        self.layers.append(nn.Linear(1000, 256)) \n",
    "        self.layers.append(nn.Dropout(0.1))\n",
    "        self.layers.append(nn.Linear(256, 32))\n",
    "        self.layers.append(nn.Sigmoid())\n",
    "        self.layers.append(nn.Dropout(0.1))\n",
    "        self.layers.append(nn.Linear(32, 7))\n",
    "        self.layers.append(nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init()\n",
    "model.load_state_dict(torch.load('models/color_model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read csv, remove nulls from Category row, shuffle and take proportions as firstly given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_column(df, column, condition):\n",
    "    return df[df[column] == condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_csv = pd.read_csv('test/color_test.csv').sample(frac = 1)\n",
    "cars_csv = cars_csv[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre defined result categories, because i trained model as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Black', 'White', 'Grey', 'Silver', 'Green', 'Blue', 'Red']\n"
     ]
    }
   ],
   "source": [
    "colors_csv = pd.read_csv('train/color_train.csv')\n",
    "result_categories = colors_csv['Color'].unique().tolist()\n",
    "print(result_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME ELAPSED: 0.00022912025451660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andghuladze/Python/venv_3.7/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME ELAPSED: 729.9070880413055\n",
      "TIME ELAPSED: 1308.5165848731995\n",
      "TIME ELAPSED: 1891.9383628368378\n",
      "TIME ELAPSED: 2481.2704198360443\n",
      "TIME ELAPSED: 3085.988711833954\n",
      "TIME ELAPSED: 3695.682202100754\n",
      "TIME ELAPSED: 4312.414589881897\n",
      "TIME ELAPSED: 4949.935772895813\n",
      "TIME ELAPSED: 5584.841130018234\n",
      "TIME ELAPSED: 6217.585563898087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Black       0.30      0.62      0.40       304\n",
      "        Blue       0.00      0.00      0.00        94\n",
      "       Green       0.00      0.00      0.00        20\n",
      "        Grey       0.12      0.34      0.17       128\n",
      "         Red       0.00      0.00      0.00        39\n",
      "      Silver       0.00      0.00      0.00       180\n",
      "       White       0.00      0.00      0.00       235\n",
      "\n",
      "    accuracy                           0.23      1000\n",
      "   macro avg       0.06      0.14      0.08      1000\n",
      "weighted avg       0.11      0.23      0.15      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andghuladze/Python/venv_3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "original_result = []\n",
    "model_result = []\n",
    "start = time.time()\n",
    "for i in range(len(cars_csv)):\n",
    "    if i % 100 == 0:\n",
    "        print(\"TIME ELAPSED: \" + str(time.time() - start))\n",
    "    \n",
    "    try:\n",
    "        car_data = object_detection_function(cars_csv.iloc[i].ID)\n",
    "        result = model(torch.stack(car_data))\n",
    "        model_res = result.argmax(axis = 0).tolist()\n",
    "        \n",
    "        winner = -1\n",
    "        highest = -1\n",
    "        for j in range(len(model_res)):\n",
    "            tmp = result[model_res[j]][j].item()\n",
    "            if tmp > highest:\n",
    "                highest = tmp\n",
    "                winner = j\n",
    "        original_result.append(cars_csv.iloc[i].Color)\n",
    "        model_result.append(result_categories[winner])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"TIME ELAPSED: \" + str(time.time() - start))\n",
    "print(classification_report(original_result, model_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check model by giving id's use this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(car_ids):\n",
    "    model_results = []\n",
    "    for i in range(len(car_ids)):\n",
    "        car_imgs = object_detection_function(car_ids[i])\n",
    "        try:\n",
    "            result = model(torch.stack(car_imgs))\n",
    "            model_res = result.argmax(axis = 0).tolist()\n",
    "            \n",
    "            winner = -1\n",
    "            highest = 0\n",
    "            for j in range(len(model_res)):\n",
    "                tmp = result[model_res[j]][j].item()\n",
    "                if tmp > highest:\n",
    "                    highest = tmp\n",
    "                    winner = j\n",
    "                \n",
    "            model_results.append(result_categories[winner])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andghuladze/Python/venv_3.7/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Black', 'Black', 'Black', 'Black']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_model([45681656, 45647533, 45658197, 45770541])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color evaluation Finished!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
